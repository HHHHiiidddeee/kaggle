{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":12681757,"sourceType":"datasetVersion","datasetId":7856290},{"sourceId":12682032,"sourceType":"datasetVersion","datasetId":7889376}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":2628.506922,"end_time":"2025-08-03T03:35:06.970486","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-03T02:51:18.463564","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntf.random.set_seed(42)\ntype_train_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/type_train_ds\")\ntype_valid_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/type_valid_ds\")\ngesture_train_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/gesture_train_ds\")\ngesture_valid_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/gesture_valid_ds\")\n# test_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/test_ds\")","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:07:38.491192Z","iopub.execute_input":"2025-08-08T15:07:38.491509Z","iopub.status.idle":"2025-08-08T15:07:53.054561Z","shell.execute_reply.started":"2025-08-08T15:07:38.491484Z","shell.execute_reply":"2025-08-08T15:07:53.053784Z"},"papermill":{"duration":16.594958,"end_time":"2025-08-03T02:51:39.402325","exception":false,"start_time":"2025-08-03T02:51:22.807367","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"2025-08-08 15:07:39.871060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1754665660.053287      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1754665660.105639      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nI0000 00:00:1754665672.922583      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:09.523607Z","iopub.execute_input":"2025-08-08T15:08:09.523899Z","iopub.status.idle":"2025-08-08T15:08:09.527542Z","shell.execute_reply.started":"2025-08-08T15:08:09.523876Z","shell.execute_reply":"2025-08-08T15:08:09.526805Z"},"papermill":{"duration":0.008264,"end_time":"2025-08-03T02:51:39.414285","exception":false,"start_time":"2025-08-03T02:51:39.406021","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(len(type_train_ds))\nprint(len(type_valid_ds))\nprint(len(gesture_train_ds))\nprint(len(gesture_valid_ds))\n\n# print(len(test_ds))","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:09.743259Z","iopub.execute_input":"2025-08-08T15:08:09.743964Z","iopub.status.idle":"2025-08-08T15:08:09.749662Z","shell.execute_reply.started":"2025-08-08T15:08:09.743941Z","shell.execute_reply":"2025-08-08T15:08:09.748970Z"},"papermill":{"duration":0.010104,"end_time":"2025-08-03T02:51:39.427561","exception":false,"start_time":"2025-08-03T02:51:39.417457","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"101\n18\n101\n18\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"for i, (inputs, targets) in enumerate(type_train_ds):\n    if i==0:\n        print(inputs[0].shape)\n        print(inputs[1].shape)\n        print(inputs[2].shape)\n        print(targets.shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:13.253400Z","iopub.execute_input":"2025-08-08T15:08:13.253988Z","iopub.status.idle":"2025-08-08T15:08:13.665853Z","shell.execute_reply.started":"2025-08-08T15:08:13.253966Z","shell.execute_reply":"2025-08-08T15:08:13.665251Z"},"papermill":{"duration":0.283311,"end_time":"2025-08-03T02:51:39.713881","exception":false,"start_time":"2025-08-03T02:51:39.430570","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(64, 80, 8, 8, 5)\n(64, 80, 19)\n(64, 14)\n(64, 1)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv3D, Conv1D, BatchNormalization, TimeDistributed\nfrom tensorflow.keras.layers import MaxPool3D, GlobalMaxPool3D, MaxPool1D, Dropout\nfrom tensorflow.keras.layers import GlobalMaxPool1D, Flatten, Dense\nfrom tensorflow.keras.layers import ReLU, ELU, Masking\nfrom tensorflow.keras.regularizers import L1, L2, L1L2\nfrom tensorflow.keras import Sequential\n\nclass CNNModel(Model):\n    def __init__(self, kernel_size3d=(3, 3, 5), kernel_size1d=3, filters_3d=[16, 32], dropout=0.2, \n                 filters_1d=[16, 32], hidden_size=64, regularizer=\"l1\", l1_penalty=0.1, l2_penalty=0.1, \n                 binary=True, **kwargs):\n        super().__init__(**kwargs)\n        self.hidden_size = hidden_size\n        \n        self.conv3d_nets = []\n        for i in range(len(filters_3d)):\n            conv3d_net = Sequential([\n                Conv3D(filters_3d[i], kernel_size3d, padding=\"same\"),\n                BatchNormalization(),\n                ReLU(),\n                MaxPool3D(pool_size=2, strides=(2, 1, 1), padding=\"same\"),\n                Dropout(dropout)\n            ], name=f\"conv3d_net_{i}\")\n            self.conv3d_nets.append(conv3d_net)\n        self.global_maxpool3d = GlobalMaxPool3D()\n\n        # self.masking = Masking(mask_value=0.0)\n        self.conv1d_nets = []\n        for i in range(len(filters_1d)):\n            conv1d_net = Sequential([\n                Conv1D(filters_1d[i], kernel_size1d, padding=\"same\", kernel_initializer=\"he_normal\"),\n                BatchNormalization(),\n                ELU(),\n                MaxPool1D(pool_size=2, strides=2, padding=\"same\"),\n                Dropout(dropout)\n            ], name=f\"conv1d_net_{i}\")\n            self.conv1d_nets.append(conv1d_net)\n\n        self.global_maxpool1d = GlobalMaxPool1D()\n\n\n        if regularizer == \"l1\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L1(l1_penalty),\n                                bias_regularizer=L1(l1_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\",\n                                  kernel_regularizer=L1(l1_penalty),\n                                  bias_regularizer=L1(l1_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L1(l1_penalty),\n                                  bias_regularizer=L1(l1_penalty))\n        elif regularizer == \"l2\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L2(l2_penalty),\n                                bias_regularizer=L2(l2_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\", \n                                  kernel_regularizer=L2(l2_penalty),\n                                  bias_regularizer=L2(l2_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L2(l2_penalty),\n                                  bias_regularizer=L2(l2_penalty))\n        elif regularizer == \"l1l2\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                bias_regularizer=L1L2(l1_penalty, l2_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\", \n                                  kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                  bias_regularizer=L1L2(l1_penalty, l2_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                  bias_regularizer=L1L2(l1_penalty, l2_penalty))\n        else:\n            self.dense0 = Dense(hidden_size, activation=\"relu\")\n            self.dense1_0 = Dense(1, activation=\"sigmoid\")\n            self.dense1_1 = Dense(18, activation=\"softmax\")\n\n        self.binary = binary\n\n    def build(self, input_shapes, training=False):\n        image_shape = input_shapes[0]\n        for i in range(len(self.conv3d_nets)):\n            self.conv3d_nets[i].build(image_shape)\n            image_shape = self.conv3d_nets[i].compute_output_shape(image_shape)\n        self.global_maxpool3d.build(image_shape)\n        image_shape = self.global_maxpool3d.compute_output_shape(image_shape)\n\n        time_series_shape = input_shapes[1]\n        for i in range(len(self.conv1d_nets)):\n            self.conv1d_nets[i].build(time_series_shape)\n            time_series_shape = self.conv1d_nets[i].compute_output_shape(time_series_shape)\n        self.global_maxpool1d.build(time_series_shape)\n        time_series_shape = self.global_maxpool1d.compute_output_shape(time_series_shape)\n\n        shape = (image_shape[0], image_shape[1] + time_series_shape[1] + input_shapes[2][1])\n\n        self.dense0.build(shape)\n        shape = self.dense0.compute_output_shape(shape)\n\n        self.dense1_0.build(shape)\n        self.dense1_1.build(shape)\n        \n\n    def call(self, inputs, training=False):\n        image_out = inputs[0]\n        for i in range(len(self.conv3d_nets)):\n            image_out = self.conv3d_nets[i](image_out, training=training)\n        image_out = self.global_maxpool3d(image_out)   # (batch, filters)\n\n        time_series_out = inputs[1]\n        for i in range(len(self.conv1d_nets)):\n            time_series_out = self.conv1d_nets[i](time_series_out, training=training)\n        time_series_out = self.global_maxpool1d(time_series_out)\n\n        out = tf.concat([image_out, time_series_out, inputs[2]], axis=-1)\n        out = self.dense0(out)\n        if self.binary:\n            out = self.dense1_0(out)\n        else:\n            out = self.dense1_1(out)\n        return out\n\n    def set_binary(self):\n        self.binary = True\n        if self.dense1_0.build == False:\n            self.dense1_0.build(input_shape=(None, self.hidden_size))\n\n    def set_multi(self):\n        self.binary = False\n        if self.dense1_1.build == False:\n            self.dense1_1.build(input_shape=(None, self.hidden_size))\n\n    def freeze_conv_timeseries(self):\n        for i in range(len(self.conv3d_nets)):\n            self.conv3d_nets[i].trainable = False\n        for i in range(len(self.conv1d_nets)):\n            self.conv1d_nets[i].trainable = False\n        self.rnn.trainable = False","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:17.329135Z","iopub.execute_input":"2025-08-08T15:08:17.329840Z","iopub.status.idle":"2025-08-08T15:08:17.350318Z","shell.execute_reply.started":"2025-08-08T15:08:17.329814Z","shell.execute_reply":"2025-08-08T15:08:17.349743Z"},"papermill":{"duration":0.027617,"end_time":"2025-08-03T02:51:39.745047","exception":false,"start_time":"2025-08-03T02:51:39.717430","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"for i, (inputs, targets) in enumerate(type_train_ds):\n    if i == 0:\n        print(inputs[0].shape)\n        print(inputs[1].shape)\n        print(inputs[2].shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:20.423823Z","iopub.execute_input":"2025-08-08T15:08:20.424548Z","iopub.status.idle":"2025-08-08T15:08:20.511950Z","shell.execute_reply.started":"2025-08-08T15:08:20.424523Z","shell.execute_reply":"2025-08-08T15:08:20.511236Z"},"papermill":{"duration":0.057592,"end_time":"2025-08-03T02:51:39.805872","exception":false,"start_time":"2025-08-03T02:51:39.748280","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"(64, 80, 8, 8, 5)\n(64, 80, 19)\n(64, 14)\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/cmi-tf-datasets/sample_weight.json') as f:\n    sample_weight_dict = json.load(f)\n\ntype_sample_weight = sample_weight_dict[\"type_sample_weight\"]\ntype_class_weight = {0: type_sample_weight[0], 1: type_sample_weight[1]}\n\ngesture_sample_weight = sample_weight_dict[\"gesture_sample_weight\"]\ngesture_class_weight = {i: gesture_sample_weight[i] for i in range(len(gesture_sample_weight))}","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:23.823569Z","iopub.execute_input":"2025-08-08T15:08:23.823813Z","iopub.status.idle":"2025-08-08T15:08:23.833453Z","shell.execute_reply.started":"2025-08-08T15:08:23.823797Z","shell.execute_reply":"2025-08-08T15:08:23.832697Z"},"papermill":{"duration":0.015952,"end_time":"2025-08-03T02:51:39.825220","exception":false,"start_time":"2025-08-03T02:51:39.809268","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def add_type_sample_weight(x, y):\n    y_int = tf.cast(y, tf.int32)\n    weight = tf.gather([type_class_weight[0], type_class_weight[1]], y_int)\n    return x, y, weight\n\ndef add_gesture_sample_weight(x, y):\n    y_arg = tf.argmax(y)\n    weight = tf.gather(gesture_sample_weight, y_arg)\n    return x, y, weight","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:24.964110Z","iopub.execute_input":"2025-08-08T15:08:24.964429Z","iopub.status.idle":"2025-08-08T15:08:24.968799Z","shell.execute_reply.started":"2025-08-08T15:08:24.964403Z","shell.execute_reply":"2025-08-08T15:08:24.968227Z"},"papermill":{"duration":0.008841,"end_time":"2025-08-03T02:51:39.837647","exception":false,"start_time":"2025-08-03T02:51:39.828806","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"type_train_ds = type_train_ds.unbatch().map(add_type_sample_weight).batch(64)\ntype_valid_ds = type_valid_ds.unbatch().map(add_type_sample_weight).batch(64)","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:36.813050Z","iopub.execute_input":"2025-08-08T15:08:36.813380Z","iopub.status.idle":"2025-08-08T15:08:36.906398Z","shell.execute_reply.started":"2025-08-08T15:08:36.813324Z","shell.execute_reply":"2025-08-08T15:08:36.905399Z"},"papermill":{"duration":0.093248,"end_time":"2025-08-03T02:51:39.934050","exception":false,"start_time":"2025-08-03T02:51:39.840802","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# gesture_train_ds = gesture_train_ds.unbatch().map(add_gesture_sample_weight).batch(16)\n# gesture_valid_ds = gesture_valid_ds.unbatch().map(add_gesture_sample_weight).batch(16)\ngesture_train_ds = gesture_train_ds.unbatch().batch(32)\ngesture_valid_ds = gesture_valid_ds.unbatch().batch(32)","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:08:37.258428Z","iopub.execute_input":"2025-08-08T15:08:37.258704Z","iopub.status.idle":"2025-08-08T15:08:37.290517Z","shell.execute_reply.started":"2025-08-08T15:08:37.258687Z","shell.execute_reply":"2025-08-08T15:08:37.289730Z"},"papermill":{"duration":0.009056,"end_time":"2025-08-03T02:51:39.946782","exception":false,"start_time":"2025-08-03T02:51:39.937726","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, CategoricalFocalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import BinaryAccuracy, F1Score, AUC\n\nmodel = CNNModel(kernel_size3d=(3, 3, 5), kernel_size1d=5, filters_3d=[8, 16, 32], dropout=0.2,\n                 filters_1d=[32, 64, 128], hidden_size=64, regularizer=\"l1l2\", \n                 l1_penalty=1e-5, l2_penalty=1e-5, binary=False)\nmodel.build(input_shapes=((None, 130, 8, 8, 5), (None, 130, 19), (None, 14)))\n# model.set_multi()\nmodel.compile(loss=BinaryCrossentropy(),\n              optimizer=Adam(learning_rate=0.0005),\n              metrics=[\"accuracy\"])\nmodel.summary()\n# model.freeze_conv_timeseries()","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:22:11.402873Z","iopub.execute_input":"2025-08-08T15:22:11.403585Z","iopub.status.idle":"2025-08-08T15:22:12.014198Z","shell.execute_reply.started":"2025-08-08T15:22:11.403564Z","shell.execute_reply":"2025-08-08T15:22:12.013486Z"},"papermill":{"duration":1.537871,"end_time":"2025-08-03T02:51:41.487729","exception":false,"start_time":"2025-08-03T02:51:39.949858","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"cnn_model_2\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn_model_2\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv3d_net_0 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m)    │         \u001b[38;5;34m1,840\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_net_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m16\u001b[0m)   │         \u001b[38;5;34m5,840\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_net_2 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │        \u001b[38;5;34m23,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling3d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalMaxPooling3D\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_0 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m3,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_1 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m10,560\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_2 (\u001b[38;5;33mSequential\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │        \u001b[38;5;34m41,600\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m11,200\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │         \u001b[38;5;34m1,170\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv3d_net_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,840</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_net_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,840</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv3d_net_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">23,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling3d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling3D</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,560</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv1d_net_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,600</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_max_pooling1d_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,200</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,170</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m98,675\u001b[0m (385.45 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,675</span> (385.45 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m98,115\u001b[0m (383.26 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">98,115</span> (383.26 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m560\u001b[0m (2.19 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">560</span> (2.19 KB)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"# from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n# checkpoint_filepath = \"/kaggle/working/cmi_binary_best_model.weights.h5\"\n# checkpoint_callback = ModelCheckpoint(\n#     filepath=checkpoint_filepath,\n#     monitor=\"val_loss\",\n#     save_best_only=True,\n#     save_weights_only=True,\n#     mode=\"min\",\n#     verbose=1\n# )\n\n# history = model.fit(type_train_ds, epochs=50, \n#                     validation_data=type_valid_ds,\n#                     callbacks=[checkpoint_callback])\n# model.load_weights(checkpoint_filepath)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T15:22:14.078529Z","iopub.execute_input":"2025-08-08T15:22:14.079046Z","iopub.status.idle":"2025-08-08T15:22:14.083124Z","shell.execute_reply.started":"2025-08-08T15:22:14.079022Z","shell.execute_reply":"2025-08-08T15:22:14.082139Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model.set_multi()\nmodel.compile(loss=CategoricalFocalCrossentropy(alpha=gesture_sample_weight, \n                                                gamma=2,\n                                                label_smoothing=0.2),\n              optimizer=Adam(learning_rate=0.0005),\n              metrics=[\"accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T15:22:14.263133Z","iopub.execute_input":"2025-08-08T15:22:14.263914Z","iopub.status.idle":"2025-08-08T15:22:14.273552Z","shell.execute_reply.started":"2025-08-08T15:22:14.263884Z","shell.execute_reply":"2025-08-08T15:22:14.272871Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"def scheduler(epoch):\n    lr = 0.0005\n    if epoch < 50:\n        return lr\n    else:\n        return lr * (1/10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T15:22:14.427887Z","iopub.execute_input":"2025-08-08T15:22:14.428210Z","iopub.status.idle":"2025-08-08T15:22:14.432876Z","shell.execute_reply.started":"2025-08-08T15:22:14.428191Z","shell.execute_reply":"2025-08-08T15:22:14.432052Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\ncheckpoint_filepath = \"/kaggle/working/cmi_best_model.weights.h5\"\ncheckpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor=\"val_accuracy\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"max\",\n    verbose=1\n)\n\nlr_callback = LearningRateScheduler(scheduler, verbose=0)\n\nhistory = model.fit(gesture_train_ds, epochs=200, \n                    validation_data=gesture_valid_ds,\n                    callbacks=[checkpoint_callback])\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2025-08-08T15:22:14.588083Z","iopub.execute_input":"2025-08-08T15:22:14.588385Z","iopub.status.idle":"2025-08-08T15:32:22.082061Z","shell.execute_reply.started":"2025-08-08T15:22:14.588356Z","shell.execute_reply":"2025-08-08T15:32:22.081476Z"},"papermill":{"duration":2581.642964,"end_time":"2025-08-03T03:34:43.135031","exception":false,"start_time":"2025-08-03T02:51:41.492067","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/200\n    202/Unknown \u001b[1m24s\u001b[0m 45ms/step - accuracy: 0.1216 - loss: 8.9071\nEpoch 1: val_accuracy improved from -inf to 0.17982, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 58ms/step - accuracy: 0.1217 - loss: 8.8977 - val_accuracy: 0.1798 - val_loss: 6.5779\nEpoch 2/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2030 - loss: 5.9297\nEpoch 2: val_accuracy improved from 0.17982 to 0.29298, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.2031 - loss: 5.9284 - val_accuracy: 0.2930 - val_loss: 5.7268\nEpoch 3/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2552 - loss: 5.4895\nEpoch 3: val_accuracy improved from 0.29298 to 0.33860, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.2553 - loss: 5.4887 - val_accuracy: 0.3386 - val_loss: 5.6129\nEpoch 4/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3033 - loss: 5.1655\nEpoch 4: val_accuracy did not improve from 0.33860\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3033 - loss: 5.1652 - val_accuracy: 0.3035 - val_loss: 5.2370\nEpoch 5/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3279 - loss: 5.0170\nEpoch 5: val_accuracy improved from 0.33860 to 0.37105, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3279 - loss: 5.0166 - val_accuracy: 0.3711 - val_loss: 5.2092\nEpoch 6/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3422 - loss: 4.8386\nEpoch 6: val_accuracy did not improve from 0.37105\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.3422 - loss: 4.8383 - val_accuracy: 0.3395 - val_loss: 5.0619\nEpoch 7/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3634 - loss: 4.6823\nEpoch 7: val_accuracy improved from 0.37105 to 0.38246, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3635 - loss: 4.6823 - val_accuracy: 0.3825 - val_loss: 4.9098\nEpoch 8/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3892 - loss: 4.5754\nEpoch 8: val_accuracy improved from 0.38246 to 0.38772, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3892 - loss: 4.5754 - val_accuracy: 0.3877 - val_loss: 4.8369\nEpoch 9/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3959 - loss: 4.4891\nEpoch 9: val_accuracy improved from 0.38772 to 0.40175, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.3960 - loss: 4.4890 - val_accuracy: 0.4018 - val_loss: 4.7936\nEpoch 10/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4164 - loss: 4.4163\nEpoch 10: val_accuracy improved from 0.40175 to 0.42456, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4162 - loss: 4.4161 - val_accuracy: 0.4246 - val_loss: 4.7764\nEpoch 11/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4366 - loss: 4.3400\nEpoch 11: val_accuracy did not improve from 0.42456\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4364 - loss: 4.3399 - val_accuracy: 0.4053 - val_loss: 4.7064\nEpoch 12/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4404 - loss: 4.2964\nEpoch 12: val_accuracy did not improve from 0.42456\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4404 - loss: 4.2958 - val_accuracy: 0.4219 - val_loss: 4.6715\nEpoch 13/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4470 - loss: 4.2255\nEpoch 13: val_accuracy did not improve from 0.42456\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4471 - loss: 4.2252 - val_accuracy: 0.4018 - val_loss: 4.8885\nEpoch 14/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4582 - loss: 4.1313\nEpoch 14: val_accuracy did not improve from 0.42456\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4582 - loss: 4.1311 - val_accuracy: 0.4053 - val_loss: 4.7607\nEpoch 15/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4686 - loss: 4.0977\nEpoch 15: val_accuracy did not improve from 0.42456\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4685 - loss: 4.0975 - val_accuracy: 0.4088 - val_loss: 4.6843\nEpoch 16/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4883 - loss: 4.0411\nEpoch 16: val_accuracy improved from 0.42456 to 0.44211, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.4882 - loss: 4.0406 - val_accuracy: 0.4421 - val_loss: 4.4509\nEpoch 17/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4950 - loss: 3.9795\nEpoch 17: val_accuracy did not improve from 0.44211\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4949 - loss: 3.9795 - val_accuracy: 0.4237 - val_loss: 4.6569\nEpoch 18/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4974 - loss: 3.9744\nEpoch 18: val_accuracy did not improve from 0.44211\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.4972 - loss: 3.9741 - val_accuracy: 0.4386 - val_loss: 4.5401\nEpoch 19/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5123 - loss: 3.9066\nEpoch 19: val_accuracy improved from 0.44211 to 0.44298, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5122 - loss: 3.9066 - val_accuracy: 0.4430 - val_loss: 4.4293\nEpoch 20/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5157 - loss: 3.8849\nEpoch 20: val_accuracy did not improve from 0.44298\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5157 - loss: 3.8849 - val_accuracy: 0.4395 - val_loss: 4.5350\nEpoch 21/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5153 - loss: 3.8260\nEpoch 21: val_accuracy improved from 0.44298 to 0.46491, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5153 - loss: 3.8259 - val_accuracy: 0.4649 - val_loss: 4.5504\nEpoch 22/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5293 - loss: 3.7810\nEpoch 22: val_accuracy did not improve from 0.46491\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5293 - loss: 3.7810 - val_accuracy: 0.4158 - val_loss: 4.4676\nEpoch 23/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5414 - loss: 3.7684\nEpoch 23: val_accuracy did not improve from 0.46491\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5414 - loss: 3.7683 - val_accuracy: 0.4579 - val_loss: 4.4386\nEpoch 24/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5448 - loss: 3.7269\nEpoch 24: val_accuracy did not improve from 0.46491\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5448 - loss: 3.7269 - val_accuracy: 0.4544 - val_loss: 4.4476\nEpoch 25/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5597 - loss: 3.6871\nEpoch 25: val_accuracy improved from 0.46491 to 0.47368, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5595 - loss: 3.6866 - val_accuracy: 0.4737 - val_loss: 4.3656\nEpoch 26/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5548 - loss: 3.6561\nEpoch 26: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5548 - loss: 3.6560 - val_accuracy: 0.4474 - val_loss: 4.3732\nEpoch 27/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5772 - loss: 3.5905\nEpoch 27: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5771 - loss: 3.5906 - val_accuracy: 0.4728 - val_loss: 4.4755\nEpoch 28/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5814 - loss: 3.5834\nEpoch 28: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5813 - loss: 3.5833 - val_accuracy: 0.4667 - val_loss: 4.5745\nEpoch 29/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5786 - loss: 3.5566\nEpoch 29: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5786 - loss: 3.5563 - val_accuracy: 0.4544 - val_loss: 4.5190\nEpoch 30/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5823 - loss: 3.5324\nEpoch 30: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5823 - loss: 3.5322 - val_accuracy: 0.4693 - val_loss: 4.3127\nEpoch 31/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5816 - loss: 3.4997\nEpoch 31: val_accuracy did not improve from 0.47368\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5816 - loss: 3.4997 - val_accuracy: 0.4579 - val_loss: 4.4934\nEpoch 32/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5953 - loss: 3.4741\nEpoch 32: val_accuracy improved from 0.47368 to 0.50000, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.5952 - loss: 3.4742 - val_accuracy: 0.5000 - val_loss: 4.3084\nEpoch 33/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6004 - loss: 3.4561\nEpoch 33: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6003 - loss: 3.4560 - val_accuracy: 0.4658 - val_loss: 4.4542\nEpoch 34/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6231 - loss: 3.4067\nEpoch 34: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6231 - loss: 3.4068 - val_accuracy: 0.4711 - val_loss: 4.4115\nEpoch 35/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6166 - loss: 3.3914\nEpoch 35: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6165 - loss: 3.3914 - val_accuracy: 0.4842 - val_loss: 4.2882\nEpoch 36/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6278 - loss: 3.3832\nEpoch 36: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6277 - loss: 3.3832 - val_accuracy: 0.4579 - val_loss: 4.6202\nEpoch 37/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6275 - loss: 3.3759\nEpoch 37: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6274 - loss: 3.3758 - val_accuracy: 0.4842 - val_loss: 4.4704\nEpoch 38/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6157 - loss: 3.3594\nEpoch 38: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6157 - loss: 3.3594 - val_accuracy: 0.4737 - val_loss: 4.5382\nEpoch 39/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6259 - loss: 3.3283\nEpoch 39: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6258 - loss: 3.3283 - val_accuracy: 0.4711 - val_loss: 4.4841\nEpoch 40/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6256 - loss: 3.3209\nEpoch 40: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6257 - loss: 3.3206 - val_accuracy: 0.4895 - val_loss: 4.2410\nEpoch 41/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6425 - loss: 3.2849\nEpoch 41: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6425 - loss: 3.2849 - val_accuracy: 0.4956 - val_loss: 4.2249\nEpoch 42/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6412 - loss: 3.2856\nEpoch 42: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6412 - loss: 3.2853 - val_accuracy: 0.4974 - val_loss: 4.3268\nEpoch 43/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6530 - loss: 3.2527\nEpoch 43: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6528 - loss: 3.2528 - val_accuracy: 0.4851 - val_loss: 4.4069\nEpoch 44/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6608 - loss: 3.1980\nEpoch 44: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6607 - loss: 3.1981 - val_accuracy: 0.4912 - val_loss: 4.2819\nEpoch 45/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6502 - loss: 3.2132\nEpoch 45: val_accuracy did not improve from 0.50000\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6502 - loss: 3.2131 - val_accuracy: 0.4991 - val_loss: 4.3686\nEpoch 46/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6531 - loss: 3.1912\nEpoch 46: val_accuracy improved from 0.50000 to 0.50965, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6531 - loss: 3.1912 - val_accuracy: 0.5096 - val_loss: 4.1954\nEpoch 47/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6682 - loss: 3.1713\nEpoch 47: val_accuracy did not improve from 0.50965\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6680 - loss: 3.1711 - val_accuracy: 0.4728 - val_loss: 4.4389\nEpoch 48/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6644 - loss: 3.1549\nEpoch 48: val_accuracy did not improve from 0.50965\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6644 - loss: 3.1551 - val_accuracy: 0.5070 - val_loss: 4.4094\nEpoch 49/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6634 - loss: 3.1468\nEpoch 49: val_accuracy did not improve from 0.50965\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6633 - loss: 3.1469 - val_accuracy: 0.4816 - val_loss: 4.5667\nEpoch 50/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6776 - loss: 3.1299\nEpoch 50: val_accuracy improved from 0.50965 to 0.51053, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6776 - loss: 3.1299 - val_accuracy: 0.5105 - val_loss: 4.2403\nEpoch 51/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6793 - loss: 3.1041\nEpoch 51: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6792 - loss: 3.1042 - val_accuracy: 0.5026 - val_loss: 4.3309\nEpoch 52/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6861 - loss: 3.1162\nEpoch 52: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6860 - loss: 3.1158 - val_accuracy: 0.4947 - val_loss: 4.3269\nEpoch 53/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6864 - loss: 3.0596\nEpoch 53: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6862 - loss: 3.0599 - val_accuracy: 0.4772 - val_loss: 4.4974\nEpoch 54/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6887 - loss: 3.0622\nEpoch 54: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6886 - loss: 3.0622 - val_accuracy: 0.4930 - val_loss: 4.4083\nEpoch 55/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6910 - loss: 3.0454\nEpoch 55: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6910 - loss: 3.0456 - val_accuracy: 0.4816 - val_loss: 4.4293\nEpoch 56/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6988 - loss: 3.0368\nEpoch 56: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6987 - loss: 3.0366 - val_accuracy: 0.4947 - val_loss: 4.3825\nEpoch 57/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6931 - loss: 3.0404\nEpoch 57: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.6930 - loss: 3.0404 - val_accuracy: 0.5061 - val_loss: 4.2812\nEpoch 58/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6933 - loss: 3.0172\nEpoch 58: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.6933 - loss: 3.0174 - val_accuracy: 0.4842 - val_loss: 4.6099\nEpoch 59/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7006 - loss: 3.0180\nEpoch 59: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7005 - loss: 3.0180 - val_accuracy: 0.4904 - val_loss: 4.3008\nEpoch 60/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7111 - loss: 2.9837\nEpoch 60: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7110 - loss: 2.9839 - val_accuracy: 0.5018 - val_loss: 4.4413\nEpoch 61/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7072 - loss: 3.0056\nEpoch 61: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7072 - loss: 3.0054 - val_accuracy: 0.4974 - val_loss: 4.3638\nEpoch 62/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7057 - loss: 2.9922\nEpoch 62: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7057 - loss: 2.9921 - val_accuracy: 0.4798 - val_loss: 4.7036\nEpoch 63/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7181 - loss: 2.9606\nEpoch 63: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7181 - loss: 2.9606 - val_accuracy: 0.5035 - val_loss: 4.3293\nEpoch 64/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7105 - loss: 2.9770\nEpoch 64: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7105 - loss: 2.9769 - val_accuracy: 0.4667 - val_loss: 4.5415\nEpoch 65/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7108 - loss: 2.9854\nEpoch 65: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7108 - loss: 2.9852 - val_accuracy: 0.4930 - val_loss: 4.3570\nEpoch 66/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7196 - loss: 2.9618\nEpoch 66: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7195 - loss: 2.9618 - val_accuracy: 0.5044 - val_loss: 4.2906\nEpoch 67/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7255 - loss: 2.9417\nEpoch 67: val_accuracy did not improve from 0.51053\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7255 - loss: 2.9416 - val_accuracy: 0.4982 - val_loss: 4.4317\nEpoch 68/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7292 - loss: 2.9150\nEpoch 68: val_accuracy improved from 0.51053 to 0.52544, saving model to /kaggle/working/cmi_best_model.weights.h5\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7291 - loss: 2.9150 - val_accuracy: 0.5254 - val_loss: 4.2747\nEpoch 69/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7339 - loss: 2.8981\nEpoch 69: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7338 - loss: 2.8980 - val_accuracy: 0.4746 - val_loss: 4.5495\nEpoch 70/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7269 - loss: 2.9266\nEpoch 70: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7268 - loss: 2.9264 - val_accuracy: 0.4956 - val_loss: 4.4513\nEpoch 71/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7328 - loss: 2.8854\nEpoch 71: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7328 - loss: 2.8854 - val_accuracy: 0.5246 - val_loss: 4.2566\nEpoch 72/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7408 - loss: 2.8916\nEpoch 72: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7407 - loss: 2.8914 - val_accuracy: 0.4974 - val_loss: 4.4865\nEpoch 73/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7438 - loss: 2.8710\nEpoch 73: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7436 - loss: 2.8712 - val_accuracy: 0.4816 - val_loss: 4.5201\nEpoch 74/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7475 - loss: 2.8580\nEpoch 74: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7475 - loss: 2.8580 - val_accuracy: 0.5088 - val_loss: 4.4585\nEpoch 75/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7464 - loss: 2.8520\nEpoch 75: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7464 - loss: 2.8520 - val_accuracy: 0.5000 - val_loss: 4.4087\nEpoch 76/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7487 - loss: 2.8635\nEpoch 76: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7487 - loss: 2.8635 - val_accuracy: 0.5070 - val_loss: 4.2819\nEpoch 77/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7380 - loss: 2.8603\nEpoch 77: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7380 - loss: 2.8600 - val_accuracy: 0.4982 - val_loss: 4.4604\nEpoch 78/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7425 - loss: 2.8608\nEpoch 78: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7425 - loss: 2.8606 - val_accuracy: 0.4781 - val_loss: 4.6008\nEpoch 79/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7460 - loss: 2.8304\nEpoch 79: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7460 - loss: 2.8304 - val_accuracy: 0.4807 - val_loss: 4.4173\nEpoch 80/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7636 - loss: 2.7909\nEpoch 80: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7635 - loss: 2.7912 - val_accuracy: 0.4535 - val_loss: 4.6533\nEpoch 81/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7483 - loss: 2.8322\nEpoch 81: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7482 - loss: 2.8322 - val_accuracy: 0.5026 - val_loss: 4.4616\nEpoch 82/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7505 - loss: 2.8134\nEpoch 82: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7505 - loss: 2.8135 - val_accuracy: 0.4482 - val_loss: 4.9022\nEpoch 83/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7615 - loss: 2.8153\nEpoch 83: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7615 - loss: 2.8152 - val_accuracy: 0.4965 - val_loss: 4.4087\nEpoch 84/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7579 - loss: 2.8204\nEpoch 84: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7579 - loss: 2.8201 - val_accuracy: 0.4693 - val_loss: 4.5377\nEpoch 85/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7684 - loss: 2.7765\nEpoch 85: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7684 - loss: 2.7767 - val_accuracy: 0.4842 - val_loss: 4.5917\nEpoch 86/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7605 - loss: 2.8064\nEpoch 86: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7605 - loss: 2.8063 - val_accuracy: 0.4719 - val_loss: 4.6583\nEpoch 87/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7642 - loss: 2.7818\nEpoch 87: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7641 - loss: 2.7818 - val_accuracy: 0.5000 - val_loss: 4.5565\nEpoch 88/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7620 - loss: 2.7848\nEpoch 88: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7620 - loss: 2.7848 - val_accuracy: 0.4640 - val_loss: 4.7782\nEpoch 89/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7670 - loss: 2.7743\nEpoch 89: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7670 - loss: 2.7743 - val_accuracy: 0.5000 - val_loss: 4.2831\nEpoch 90/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7694 - loss: 2.7611\nEpoch 90: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7694 - loss: 2.7611 - val_accuracy: 0.4868 - val_loss: 4.6570\nEpoch 91/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7707 - loss: 2.7634\nEpoch 91: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.7706 - loss: 2.7634 - val_accuracy: 0.4877 - val_loss: 4.3955\nEpoch 92/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7762 - loss: 2.7298\nEpoch 92: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7761 - loss: 2.7300 - val_accuracy: 0.5158 - val_loss: 4.4199\nEpoch 93/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7693 - loss: 2.7590\nEpoch 93: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7693 - loss: 2.7589 - val_accuracy: 0.4956 - val_loss: 4.4374\nEpoch 94/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7764 - loss: 2.7488\nEpoch 94: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7764 - loss: 2.7486 - val_accuracy: 0.5079 - val_loss: 4.4006\nEpoch 95/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7810 - loss: 2.7174\nEpoch 95: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7809 - loss: 2.7176 - val_accuracy: 0.5123 - val_loss: 4.4068\nEpoch 96/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7703 - loss: 2.7608\nEpoch 96: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7704 - loss: 2.7604 - val_accuracy: 0.4798 - val_loss: 4.5738\nEpoch 97/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7726 - loss: 2.7470\nEpoch 97: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7726 - loss: 2.7469 - val_accuracy: 0.4737 - val_loss: 4.5835\nEpoch 98/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7808 - loss: 2.7262\nEpoch 98: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7807 - loss: 2.7264 - val_accuracy: 0.4579 - val_loss: 4.6631\nEpoch 99/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7857 - loss: 2.7201\nEpoch 99: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7857 - loss: 2.7201 - val_accuracy: 0.5088 - val_loss: 4.5016\nEpoch 100/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7728 - loss: 2.7385\nEpoch 100: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7728 - loss: 2.7381 - val_accuracy: 0.4904 - val_loss: 4.4362\nEpoch 101/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7929 - loss: 2.7054\nEpoch 101: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7927 - loss: 2.7054 - val_accuracy: 0.4904 - val_loss: 4.5781\nEpoch 102/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7934 - loss: 2.6864\nEpoch 102: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7934 - loss: 2.6864 - val_accuracy: 0.4781 - val_loss: 4.6770\nEpoch 103/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7881 - loss: 2.6926\nEpoch 103: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7881 - loss: 2.6927 - val_accuracy: 0.4947 - val_loss: 4.4880\nEpoch 104/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7955 - loss: 2.6869\nEpoch 104: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7953 - loss: 2.6872 - val_accuracy: 0.4596 - val_loss: 4.7770\nEpoch 105/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7900 - loss: 2.6988\nEpoch 105: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7901 - loss: 2.6987 - val_accuracy: 0.4772 - val_loss: 4.6433\nEpoch 106/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7979 - loss: 2.6804\nEpoch 106: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7978 - loss: 2.6803 - val_accuracy: 0.4754 - val_loss: 4.5357\nEpoch 107/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7940 - loss: 2.6739\nEpoch 107: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7940 - loss: 2.6738 - val_accuracy: 0.5202 - val_loss: 4.2415\nEpoch 108/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7997 - loss: 2.6497\nEpoch 108: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7996 - loss: 2.6499 - val_accuracy: 0.4746 - val_loss: 4.6349\nEpoch 109/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8028 - loss: 2.6661\nEpoch 109: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8028 - loss: 2.6661 - val_accuracy: 0.4895 - val_loss: 4.5122\nEpoch 110/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7929 - loss: 2.6559\nEpoch 110: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7930 - loss: 2.6559 - val_accuracy: 0.4632 - val_loss: 4.6416\nEpoch 111/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7923 - loss: 2.6695\nEpoch 111: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7924 - loss: 2.6693 - val_accuracy: 0.4886 - val_loss: 4.4448\nEpoch 112/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8081 - loss: 2.6489\nEpoch 112: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 2.6490 - val_accuracy: 0.5026 - val_loss: 4.5039\nEpoch 113/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7995 - loss: 2.6478\nEpoch 113: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7993 - loss: 2.6480 - val_accuracy: 0.5158 - val_loss: 4.3536\nEpoch 114/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7954 - loss: 2.6550\nEpoch 114: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7953 - loss: 2.6549 - val_accuracy: 0.4746 - val_loss: 4.6232\nEpoch 115/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8058 - loss: 2.6423\nEpoch 115: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8058 - loss: 2.6422 - val_accuracy: 0.4877 - val_loss: 4.5819\nEpoch 116/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8009 - loss: 2.6457\nEpoch 116: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8009 - loss: 2.6457 - val_accuracy: 0.4974 - val_loss: 4.4263\nEpoch 117/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7995 - loss: 2.6577\nEpoch 117: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.7995 - loss: 2.6576 - val_accuracy: 0.4535 - val_loss: 4.7329\nEpoch 118/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8128 - loss: 2.6250\nEpoch 118: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8127 - loss: 2.6250 - val_accuracy: 0.5044 - val_loss: 4.4449\nEpoch 119/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8007 - loss: 2.6496\nEpoch 119: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8007 - loss: 2.6494 - val_accuracy: 0.4763 - val_loss: 4.5411\nEpoch 120/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8097 - loss: 2.6305\nEpoch 120: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8097 - loss: 2.6304 - val_accuracy: 0.4851 - val_loss: 4.5520\nEpoch 121/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8080 - loss: 2.6420\nEpoch 121: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8080 - loss: 2.6418 - val_accuracy: 0.4561 - val_loss: 4.7375\nEpoch 122/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8196 - loss: 2.6265\nEpoch 122: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8195 - loss: 2.6265 - val_accuracy: 0.4833 - val_loss: 4.6721\nEpoch 123/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8124 - loss: 2.6058\nEpoch 123: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8123 - loss: 2.6059 - val_accuracy: 0.4711 - val_loss: 4.6197\nEpoch 124/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8289 - loss: 2.6087\nEpoch 124: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8287 - loss: 2.6088 - val_accuracy: 0.4904 - val_loss: 4.4663\nEpoch 125/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8180 - loss: 2.6101\nEpoch 125: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8180 - loss: 2.6102 - val_accuracy: 0.4851 - val_loss: 4.5484\nEpoch 126/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8184 - loss: 2.5965\nEpoch 126: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8183 - loss: 2.5965 - val_accuracy: 0.5158 - val_loss: 4.4285\nEpoch 127/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8163 - loss: 2.6057\nEpoch 127: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8163 - loss: 2.6056 - val_accuracy: 0.4956 - val_loss: 4.7127\nEpoch 128/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8186 - loss: 2.5943\nEpoch 128: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8186 - loss: 2.5943 - val_accuracy: 0.5035 - val_loss: 4.5219\nEpoch 129/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8172 - loss: 2.5804\nEpoch 129: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8171 - loss: 2.5805 - val_accuracy: 0.4772 - val_loss: 4.6257\nEpoch 130/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8210 - loss: 2.6059\nEpoch 130: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8210 - loss: 2.6059 - val_accuracy: 0.5035 - val_loss: 4.5301\nEpoch 131/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8268 - loss: 2.5883\nEpoch 131: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8265 - loss: 2.5885 - val_accuracy: 0.4544 - val_loss: 4.6897\nEpoch 132/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8294 - loss: 2.5741\nEpoch 132: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8294 - loss: 2.5740 - val_accuracy: 0.4974 - val_loss: 4.4689\nEpoch 133/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8127 - loss: 2.6021\nEpoch 133: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8128 - loss: 2.6019 - val_accuracy: 0.4833 - val_loss: 4.5872\nEpoch 134/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8177 - loss: 2.5789\nEpoch 134: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8177 - loss: 2.5789 - val_accuracy: 0.5070 - val_loss: 4.4609\nEpoch 135/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8315 - loss: 2.5729\nEpoch 135: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8314 - loss: 2.5729 - val_accuracy: 0.4868 - val_loss: 4.4403\nEpoch 136/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 2.5573\nEpoch 136: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8345 - loss: 2.5573 - val_accuracy: 0.4526 - val_loss: 4.7717\nEpoch 137/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8318 - loss: 2.5699\nEpoch 137: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8318 - loss: 2.5698 - val_accuracy: 0.5096 - val_loss: 4.4093\nEpoch 138/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8286 - loss: 2.5656\nEpoch 138: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8285 - loss: 2.5656 - val_accuracy: 0.4728 - val_loss: 4.6017\nEpoch 139/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8309 - loss: 2.5571\nEpoch 139: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8308 - loss: 2.5573 - val_accuracy: 0.4930 - val_loss: 4.6110\nEpoch 140/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8275 - loss: 2.5697\nEpoch 140: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8274 - loss: 2.5696 - val_accuracy: 0.4798 - val_loss: 4.6705\nEpoch 141/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8286 - loss: 2.5715\nEpoch 141: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8286 - loss: 2.5713 - val_accuracy: 0.5000 - val_loss: 4.5364\nEpoch 142/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8237 - loss: 2.5754\nEpoch 142: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8237 - loss: 2.5753 - val_accuracy: 0.5035 - val_loss: 4.5213\nEpoch 143/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8412 - loss: 2.5313\nEpoch 143: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8411 - loss: 2.5314 - val_accuracy: 0.5158 - val_loss: 4.3771\nEpoch 144/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8413 - loss: 2.5452\nEpoch 144: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8412 - loss: 2.5452 - val_accuracy: 0.4772 - val_loss: 4.6907\nEpoch 145/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8304 - loss: 2.5487\nEpoch 145: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8305 - loss: 2.5486 - val_accuracy: 0.4719 - val_loss: 4.6055\nEpoch 146/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8389 - loss: 2.5404\nEpoch 146: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8389 - loss: 2.5404 - val_accuracy: 0.5044 - val_loss: 4.3654\nEpoch 147/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8364 - loss: 2.5452\nEpoch 147: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8363 - loss: 2.5452 - val_accuracy: 0.4395 - val_loss: 4.6869\nEpoch 148/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8402 - loss: 2.5454\nEpoch 148: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8402 - loss: 2.5454 - val_accuracy: 0.5061 - val_loss: 4.3967\nEpoch 149/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8405 - loss: 2.5306\nEpoch 149: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8404 - loss: 2.5307 - val_accuracy: 0.4711 - val_loss: 4.5742\nEpoch 150/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8272 - loss: 2.5447\nEpoch 150: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8272 - loss: 2.5447 - val_accuracy: 0.4851 - val_loss: 4.7450\nEpoch 151/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8346 - loss: 2.5647\nEpoch 151: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8346 - loss: 2.5645 - val_accuracy: 0.4982 - val_loss: 4.5202\nEpoch 152/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8435 - loss: 2.5253\nEpoch 152: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8433 - loss: 2.5254 - val_accuracy: 0.4877 - val_loss: 4.6704\nEpoch 153/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8319 - loss: 2.5376\nEpoch 153: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8319 - loss: 2.5376 - val_accuracy: 0.4816 - val_loss: 4.6239\nEpoch 154/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8355 - loss: 2.5264\nEpoch 154: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8354 - loss: 2.5264 - val_accuracy: 0.4807 - val_loss: 4.5652\nEpoch 155/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8473 - loss: 2.5121\nEpoch 155: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8472 - loss: 2.5121 - val_accuracy: 0.4912 - val_loss: 4.5813\nEpoch 156/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8408 - loss: 2.5500\nEpoch 156: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8408 - loss: 2.5499 - val_accuracy: 0.4833 - val_loss: 4.5758\nEpoch 157/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8503 - loss: 2.5087\nEpoch 157: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8502 - loss: 2.5088 - val_accuracy: 0.5184 - val_loss: 4.4209\nEpoch 158/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8329 - loss: 2.5201\nEpoch 158: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8329 - loss: 2.5200 - val_accuracy: 0.4754 - val_loss: 4.6816\nEpoch 159/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8324 - loss: 2.5576\nEpoch 159: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8324 - loss: 2.5575 - val_accuracy: 0.4825 - val_loss: 4.6019\nEpoch 160/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8466 - loss: 2.5143\nEpoch 160: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8466 - loss: 2.5142 - val_accuracy: 0.4939 - val_loss: 4.5696\nEpoch 161/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8478 - loss: 2.5061\nEpoch 161: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8477 - loss: 2.5062 - val_accuracy: 0.5123 - val_loss: 4.4462\nEpoch 162/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8483 - loss: 2.4974\nEpoch 162: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8482 - loss: 2.4974 - val_accuracy: 0.5105 - val_loss: 4.4747\nEpoch 163/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8399 - loss: 2.5296\nEpoch 163: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8399 - loss: 2.5296 - val_accuracy: 0.4974 - val_loss: 4.4784\nEpoch 164/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8542 - loss: 2.4933\nEpoch 164: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8541 - loss: 2.4933 - val_accuracy: 0.4904 - val_loss: 4.5224\nEpoch 165/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8464 - loss: 2.5087\nEpoch 165: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8464 - loss: 2.5087 - val_accuracy: 0.4816 - val_loss: 4.6189\nEpoch 166/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8460 - loss: 2.4978\nEpoch 166: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8460 - loss: 2.4979 - val_accuracy: 0.4965 - val_loss: 4.4902\nEpoch 167/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8391 - loss: 2.5193\nEpoch 167: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8392 - loss: 2.5189 - val_accuracy: 0.5053 - val_loss: 4.5308\nEpoch 168/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8491 - loss: 2.5025\nEpoch 168: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8491 - loss: 2.5023 - val_accuracy: 0.4991 - val_loss: 4.5327\nEpoch 169/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8563 - loss: 2.5041\nEpoch 169: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8563 - loss: 2.5040 - val_accuracy: 0.4947 - val_loss: 4.4910\nEpoch 170/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8452 - loss: 2.4975\nEpoch 170: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8452 - loss: 2.4976 - val_accuracy: 0.5053 - val_loss: 4.4955\nEpoch 171/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8461 - loss: 2.4920\nEpoch 171: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8461 - loss: 2.4922 - val_accuracy: 0.4895 - val_loss: 4.4873\nEpoch 172/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8468 - loss: 2.4888\nEpoch 172: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8468 - loss: 2.4888 - val_accuracy: 0.4921 - val_loss: 4.4854\nEpoch 173/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8545 - loss: 2.4698\nEpoch 173: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8545 - loss: 2.4700 - val_accuracy: 0.4693 - val_loss: 4.5740\nEpoch 174/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8493 - loss: 2.4989\nEpoch 174: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8493 - loss: 2.4989 - val_accuracy: 0.4939 - val_loss: 4.5317\nEpoch 175/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8575 - loss: 2.4781\nEpoch 175: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8574 - loss: 2.4782 - val_accuracy: 0.4719 - val_loss: 4.6019\nEpoch 176/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8621 - loss: 2.4738\nEpoch 176: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8621 - loss: 2.4737 - val_accuracy: 0.4754 - val_loss: 4.6152\nEpoch 177/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8524 - loss: 2.4904\nEpoch 177: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8524 - loss: 2.4904 - val_accuracy: 0.5009 - val_loss: 4.4872\nEpoch 178/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8527 - loss: 2.4819\nEpoch 178: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8527 - loss: 2.4819 - val_accuracy: 0.5070 - val_loss: 4.5181\nEpoch 179/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8510 - loss: 2.4693\nEpoch 179: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8510 - loss: 2.4694 - val_accuracy: 0.4982 - val_loss: 4.4873\nEpoch 180/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8563 - loss: 2.4825\nEpoch 180: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8562 - loss: 2.4824 - val_accuracy: 0.5035 - val_loss: 4.5926\nEpoch 181/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8518 - loss: 2.4841\nEpoch 181: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8518 - loss: 2.4840 - val_accuracy: 0.4930 - val_loss: 4.5301\nEpoch 182/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8548 - loss: 2.4716\nEpoch 182: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8548 - loss: 2.4714 - val_accuracy: 0.5123 - val_loss: 4.4419\nEpoch 183/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8546 - loss: 2.4945\nEpoch 183: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8546 - loss: 2.4943 - val_accuracy: 0.4912 - val_loss: 4.6773\nEpoch 184/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8627 - loss: 2.4605\nEpoch 184: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8626 - loss: 2.4607 - val_accuracy: 0.4886 - val_loss: 4.5940\nEpoch 185/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8586 - loss: 2.4560\nEpoch 185: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8585 - loss: 2.4562 - val_accuracy: 0.5044 - val_loss: 4.5223\nEpoch 186/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8629 - loss: 2.4432\nEpoch 186: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8628 - loss: 2.4433 - val_accuracy: 0.5105 - val_loss: 4.4183\nEpoch 187/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8564 - loss: 2.4743\nEpoch 187: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8564 - loss: 2.4743 - val_accuracy: 0.4825 - val_loss: 4.7363\nEpoch 188/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8607 - loss: 2.4641\nEpoch 188: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8606 - loss: 2.4640 - val_accuracy: 0.4842 - val_loss: 4.6309\nEpoch 189/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8617 - loss: 2.4484\nEpoch 189: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8616 - loss: 2.4484 - val_accuracy: 0.4921 - val_loss: 4.5123\nEpoch 190/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8553 - loss: 2.4615\nEpoch 190: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8554 - loss: 2.4612 - val_accuracy: 0.4807 - val_loss: 4.7361\nEpoch 191/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8609 - loss: 2.4567\nEpoch 191: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8608 - loss: 2.4567 - val_accuracy: 0.5254 - val_loss: 4.4254\nEpoch 192/200\n\u001b[1m200/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8616 - loss: 2.4631\nEpoch 192: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8616 - loss: 2.4630 - val_accuracy: 0.4816 - val_loss: 4.6712\nEpoch 193/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8653 - loss: 2.4450\nEpoch 193: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8652 - loss: 2.4452 - val_accuracy: 0.5149 - val_loss: 4.5033\nEpoch 194/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8587 - loss: 2.4422\nEpoch 194: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8587 - loss: 2.4422 - val_accuracy: 0.5026 - val_loss: 4.5529\nEpoch 195/200\n\u001b[1m199/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8601 - loss: 2.4623\nEpoch 195: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8601 - loss: 2.4621 - val_accuracy: 0.5140 - val_loss: 4.4676\nEpoch 196/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8629 - loss: 2.4572\nEpoch 196: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8630 - loss: 2.4569 - val_accuracy: 0.4895 - val_loss: 4.5807\nEpoch 197/200\n\u001b[1m198/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8599 - loss: 2.4592\nEpoch 197: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8598 - loss: 2.4594 - val_accuracy: 0.5061 - val_loss: 4.5847\nEpoch 198/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8535 - loss: 2.4679\nEpoch 198: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8535 - loss: 2.4679 - val_accuracy: 0.5018 - val_loss: 4.4548\nEpoch 199/200\n\u001b[1m201/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8561 - loss: 2.4590\nEpoch 199: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8561 - loss: 2.4590 - val_accuracy: 0.5096 - val_loss: 4.5090\nEpoch 200/200\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8696 - loss: 2.4455\nEpoch 200: val_accuracy did not improve from 0.52544\n\u001b[1m202/202\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8696 - loss: 2.4455 - val_accuracy: 0.5053 - val_loss: 4.4408\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/cmi-tf-datasets/mapping.json') as f:\n    mapping_dict = json.load(f)\n\ngesture_mapping = mapping_dict[\"gesture_mapping\"]\ninv_gesture_mapping = {value: key for key, value in gesture_mapping.items()}\n\nnum2gesture = np.vectorize(lambda x: inv_gesture_mapping[x])","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:09.922811Z","iopub.execute_input":"2025-08-07T15:09:09.923457Z","iopub.status.idle":"2025-08-07T15:09:09.932303Z","shell.execute_reply.started":"2025-08-07T15:09:09.923429Z","shell.execute_reply":"2025-08-07T15:09:09.931593Z"},"papermill":{"duration":1.007517,"end_time":"2025-08-03T03:34:45.123831","exception":false,"start_time":"2025-08-03T03:34:44.116314","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"non_target_gestures = [\"Drink from bottle/cup\", \"Glasses on/off\", \"Pull air toward your face\",\n                       \"Pinch knee/leg skin\", \"Scratch knee/leg skin\", \"Write name on leg\",\n                       \"Text on phone\", \"Feel around in tray and pull out an object\",\n                       \"Write name in air\", \"Wave hello\"]\n\ndef map_non_target(y_ind):\n    y_pred = inv_gesture_mapping[y_ind]\n    if y_ind == 3:\n        y_ind = 2\n    elif y_ind == 4:\n        y_ind = 3\n    elif y_ind == 6:\n        y_ind = 4\n    elif y_ind == 7:\n        y_ind = 5\n    elif y_ind == 9:\n        y_ind = 6\n    elif y_ind == 10:\n        y_ind = 7\n    if y_pred in non_target_gestures:\n        y_ind = 8\n    return y_ind\n\nvectorize_map_non_target = np.vectorize(map_non_target)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:10.125083Z","iopub.execute_input":"2025-08-07T15:09:10.125381Z","iopub.status.idle":"2025-08-07T15:09:10.130322Z","shell.execute_reply.started":"2025-08-07T15:09:10.125359Z","shell.execute_reply":"2025-08-07T15:09:10.129631Z"},"papermill":{"duration":0.893904,"end_time":"2025-08-03T03:34:46.958634","exception":false,"start_time":"2025-08-03T03:34:46.064730","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_tensor = np.zeros((9, 9), dtype=np.int32)\nfor i, (inputs, labels) in enumerate(gesture_valid_ds):\n    labels_pred = model.predict(inputs, verbose=0)\n    labels_pred = tf.argmax(labels_pred, axis=-1).numpy()\n    labels_pred = vectorize_map_non_target(labels_pred)\n    labels_true = tf.argmax(labels, axis=-1).numpy()\n    labels_true = vectorize_map_non_target(labels_true)\n    conf_tensor += tf.math.confusion_matrix(labels_true, labels_pred, num_classes=9)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:10.305305Z","iopub.execute_input":"2025-08-07T15:09:10.305600Z","iopub.status.idle":"2025-08-07T15:09:15.354054Z","shell.execute_reply.started":"2025-08-07T15:09:10.305576Z","shell.execute_reply":"2025-08-07T15:09:15.353267Z"},"papermill":{"duration":9.433641,"end_time":"2025-08-03T03:34:57.320803","exception":false,"start_time":"2025-08-03T03:34:47.887162","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precisions = []\nrecalls = []\nf1s = []\n\nfor i in range(9):\n    column = conf_tensor[i, :]\n    row = conf_tensor[:, i]\n    precision = column[i] / tf.math.reduce_sum(column)\n    recall = row[i] / tf.math.reduce_sum(row)\n    inv_f1 = (1/precision + 1/recall)/2\n    f1 = 1/inv_f1\n    precisions.append(precision)\n    recalls.append(recall)\n    f1s.append(f1)\nprint(f\"F1 score mean: {np.round(np.mean(f1s), 3)}\")","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:15.355412Z","iopub.execute_input":"2025-08-07T15:09:15.355724Z","iopub.status.idle":"2025-08-07T15:09:15.400815Z","shell.execute_reply.started":"2025-08-07T15:09:15.355700Z","shell.execute_reply":"2025-08-07T15:09:15.400280Z"},"papermill":{"duration":1.01372,"end_time":"2025-08-03T03:34:59.223013","exception":false,"start_time":"2025-08-03T03:34:58.209293","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# save_path = os.path.join(\"/kaggle/working/\", \"cmi_model.weights.h5\")\n# model.save_weights(save_path)","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:15.401462Z","iopub.execute_input":"2025-08-07T15:09:15.401688Z","iopub.status.idle":"2025-08-07T15:09:15.404871Z","shell.execute_reply.started":"2025-08-07T15:09:15.401663Z","shell.execute_reply":"2025-08-07T15:09:15.404145Z"},"papermill":{"duration":0.98532,"end_time":"2025-08-03T03:35:01.162808","exception":false,"start_time":"2025-08-03T03:35:00.177488","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_model = CNNModel(kernel_size3d=(3, 3, 5), kernel_size1d=5, filters_3d=[8, 16, 32, 64], dropout=0.2,\n                     filters_1d=[32, 64, 128, 256], hidden_size=128, regularizer=\"l1l2\", \n                     l1_penalty=1e-5, l2_penalty=1e-5, binary=False)\nnew_model.build(input_shapes=((None, 100, 8, 8, 5), (None, 100, 19), (None, 14)))\nnew_model.load_weights(checkpoint_filepath)\nnew_model.summary()","metadata":{"execution":{"iopub.status.busy":"2025-08-07T15:09:48.155512Z","iopub.execute_input":"2025-08-07T15:09:48.156066Z","iopub.status.idle":"2025-08-07T15:09:48.381551Z","shell.execute_reply.started":"2025-08-07T15:09:48.156043Z","shell.execute_reply":"2025-08-07T15:09:48.381008Z"},"papermill":{"duration":1.17719,"end_time":"2025-08-03T03:35:03.214875","exception":false,"start_time":"2025-08-03T03:35:02.037685","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}