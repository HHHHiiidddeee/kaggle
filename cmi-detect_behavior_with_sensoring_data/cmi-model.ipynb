{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":102335,"databundleVersionId":12518947,"sourceType":"competition"},{"sourceId":12641873,"sourceType":"datasetVersion","datasetId":7856290},{"sourceId":12660724,"sourceType":"datasetVersion","datasetId":7889376}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"papermill":{"default_parameters":{},"duration":2628.506922,"end_time":"2025-08-03T03:35:06.970486","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-08-03T02:51:18.463564","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import Model\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntf.random.set_seed(42)\ntype_train_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/type_train_ds\")\ntype_valid_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/type_valid_ds\")\ngesture_train_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/gesture_train_ds\")\ngesture_valid_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/gesture_valid_ds\")\n# test_ds = tf.data.experimental.load(\"/kaggle/input/cmi-tf-datasets/test_ds\")","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:05.993201Z","iopub.execute_input":"2025-08-03T16:09:05.993708Z","iopub.status.idle":"2025-08-03T16:09:07.113624Z","shell.execute_reply.started":"2025-08-03T16:09:05.993683Z","shell.execute_reply":"2025-08-03T16:09:07.113075Z"},"papermill":{"duration":16.594958,"end_time":"2025-08-03T02:51:39.402325","exception":false,"start_time":"2025-08-03T02:51:22.807367","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:08.476056Z","iopub.execute_input":"2025-08-03T16:09:08.476341Z","iopub.status.idle":"2025-08-03T16:09:08.479909Z","shell.execute_reply.started":"2025-08-03T16:09:08.476320Z","shell.execute_reply":"2025-08-03T16:09:08.479266Z"},"papermill":{"duration":0.008264,"end_time":"2025-08-03T02:51:39.414285","exception":false,"start_time":"2025-08-03T02:51:39.406021","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(type_train_ds))\nprint(len(type_valid_ds))\nprint(len(gesture_train_ds))\nprint(len(gesture_valid_ds))\n\nprint(len(test_ds))","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:08.640456Z","iopub.execute_input":"2025-08-03T16:09:08.640713Z","iopub.status.idle":"2025-08-03T16:09:08.647175Z","shell.execute_reply.started":"2025-08-03T16:09:08.640694Z","shell.execute_reply":"2025-08-03T16:09:08.646455Z"},"papermill":{"duration":0.010104,"end_time":"2025-08-03T02:51:39.427561","exception":false,"start_time":"2025-08-03T02:51:39.417457","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, (inputs, targets) in enumerate(type_train_ds):\n    if i==0:\n        print(inputs[0].shape)\n        print(targets.shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:13.865741Z","iopub.execute_input":"2025-08-03T16:09:13.866044Z","iopub.status.idle":"2025-08-03T16:09:14.127662Z","shell.execute_reply.started":"2025-08-03T16:09:13.866022Z","shell.execute_reply":"2025-08-03T16:09:14.127043Z"},"papermill":{"duration":0.283311,"end_time":"2025-08-03T02:51:39.713881","exception":false,"start_time":"2025-08-03T02:51:39.430570","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.layers import Conv2D, Conv1D, BatchNormalization, TimeDistributed\nfrom tensorflow.keras.layers import MaxPool2D, GlobalMaxPool2D, AveragePooling1D, Dropout\nfrom tensorflow.keras.layers import SimpleRNN, LSTM, GRU, Bidirectional, Flatten, Dense\nfrom tensorflow.keras.layers import ReLU, ELU, Masking\nfrom tensorflow.keras.regularizers import L1, L2, L1L2\nfrom tensorflow.keras import Sequential\n\nclass RNNModel(Model):\n    def __init__(self, kernel_size2d=3, kernel_size1d=3, filters_2d=[16, 32], dropout=0.2, \n                 filters_1d=[16, 32], num_rnn_layers=1, rnn_hidden_size=32, mode=\"RNN\", \n                 bidirectional=False, hidden_size=64, regularizer=\"l1\", l1_penalty=0.1, l2_penalty=0.1, \n                 binary=True, **kwargs):\n        super().__init__(**kwargs)\n        self.hidden_size = hidden_size\n        self.bidirectional = bidirectional\n        \n        self.conv2d_nets = []\n        for i in range(len(filters_2d)):\n            conv2d_net = Sequential([\n                TimeDistributed(Conv2D(filters_2d[i], kernel_size2d, padding=\"same\")),\n                TimeDistributed(BatchNormalization()),\n                TimeDistributed(ReLU()),\n                TimeDistributed(MaxPool2D(pool_size=2, strides=2, padding=\"same\")),\n                TimeDistributed(Dropout(dropout))\n            ], name=f\"conv2d_net_{i}\")\n            self.conv2d_nets.append(conv2d_net)\n        self.global_maxpool = TimeDistributed(GlobalMaxPool2D(), name=\"global_maxpool2d\")\n\n        self.masking = Masking(mask_value=0.0)\n        self.conv1d_nets = []\n        for i in range(len(filters_1d)):\n            conv1d_net = Sequential([\n                Conv1D(filters_1d[i], kernel_size1d, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False),\n                BatchNormalization(),\n                ELU(),\n                AveragePooling1D(pool_size=2, strides=2, padding=\"same\"),\n                Dropout(dropout)\n            ], name=f\"conv1d_net_{i}\")\n            self.conv1d_nets.append(conv1d_net)\n\n        self.rnns = []\n        self.skip_dense = Dense(rnn_hidden_size*2, name=\"skip_connection_dense_bidirectional\")\n        for i in range(num_rnn_layers):\n            return_sequences = True if i!=num_rnn_layers-1 else False\n            if mode == \"RNN\":\n                rnn = SimpleRNN(rnn_hidden_size, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"orthogonal\", \n                                dropout=dropout, recurrent_dropout=dropout, return_sequences=return_sequences)\n            elif mode == \"LSTM\":\n                rnn = LSTM(rnn_hidden_size, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"orthogonal\", \n                           dropout=dropout, recurrent_dropout=dropout, return_sequences=return_sequences)\n            else:\n                rnn = GRU(rnn_hidden_size, kernel_initializer=\"glorot_normal\", recurrent_initializer=\"orthogonal\", \n                          dropout=dropout, recurrent_dropout=dropout, return_sequences=return_sequences)\n            if bidirectional:\n                rnn = Bidirectional(rnn, name=f\"{mode}_{i}\")\n            self.rnns.append(rnn)\n        \n        # self.dense_flat = Sequential([\n        #     Dense(1, activation=\"relu\"),\n        #     Flatten()\n        # ], name=\"dense_and_flatten\")\n\n        if regularizer == \"l1\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L1(l1_penalty),\n                                bias_regularizer=L1(l1_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\",\n                                  kernel_regularizer=L1(l1_penalty),\n                                  bias_regularizer=L1(l1_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L1(l1_penalty),\n                                  bias_regularizer=L1(l1_penalty))\n        elif regularizer == \"l2\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L2(l2_penalty),\n                                bias_regularizer=L2(l2_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\", \n                                  kernel_regularizer=L2(l2_penalty),\n                                  bias_regularizer=L2(l2_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L2(l2_penalty),\n                                  bias_regularizer=L2(l2_penalty))\n        elif regularizer == \"l1l2\":\n            self.dense0 = Dense(hidden_size, activation=\"relu\", \n                                kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                bias_regularizer=L1L2(l1_penalty, l2_penalty))\n            self.dense1_0 = Dense(1, activation=\"sigmoid\", \n                                  kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                  bias_regularizer=L1L2(l1_penalty, l2_penalty))\n            self.dense1_1 = Dense(18, activation=\"softmax\", kernel_initializer=\"glorot_normal\",\n                                  kernel_regularizer=L1L2(l1_penalty, l2_penalty),\n                                  bias_regularizer=L1L2(l1_penalty, l2_penalty))\n        else:\n            self.dense0 = Dense(hidden_size, activation=\"relu\")\n            self.dense1_0 = Dense(1, activation=\"sigmoid\")\n            self.dense1_1 = Dense(18, activation=\"softmax\")\n\n        self.binary = binary\n\n    def build(self, input_shapes, training=False):\n        image_shape = input_shapes[0]\n        for i in range(len(self.conv2d_nets)):\n            self.conv2d_nets[i].build(image_shape)\n            image_shape = self.conv2d_nets[i].compute_output_shape(image_shape)\n        self.global_maxpool.build(image_shape)\n        image_shape = self.global_maxpool.compute_output_shape(image_shape)\n\n        time_series_shape = input_shapes[1]\n        shape = (image_shape[0], image_shape[1], image_shape[2] + time_series_shape[2])\n        self.masking.build(shape)\n        shape = self.masking.compute_output_shape(shape)\n        for i in range(len(self.conv1d_nets)):\n            self.conv1d_nets[i].build(shape)\n            shape = self.conv1d_nets[i].compute_output_shape(shape)\n\n        self.skip_dense.build(shape)\n        for i in range(len(self.rnns)):\n            self.rnns[i].build(shape)\n            shape = self.rnns[i].compute_output_shape(shape)\n        # self.rnn.build(shape)\n        # shape = self.rnn.compute_output_shape(shape)\n        shape = (shape[0], shape[1] + input_shapes[2][1])\n\n        self.dense0.build(shape)\n        shape = self.dense0.compute_output_shape(shape)\n\n        self.dense1_0.build(shape)\n        self.dense1_1.build(shape)\n        \n\n    def call(self, inputs, training=False):\n        image_out = inputs[0]\n        for i in range(len(self.conv2d_nets)):\n            image_out = self.conv2d_nets[i](image_out, training=training)\n        image_out = self.global_maxpool(image_out)   # (batch, filters)\n\n        out = tf.concat([image_out, inputs[1]], axis=-1)\n        for i in range(len(self.conv1d_nets)):\n            out = self.conv1d_nets[i](out, training=training)\n\n        out = self.masking(out)\n        for i in range(len(self.rnns)):\n            rnn_out = self.rnns[i](out, training=training)\n            if i==0 and len(self.rnns)!=1:\n                out = self.skip_dense(out) if self.bidirectional else out\n                out = rnn_out + out\n            elif i < len(self.rnns)-1:\n                out = rnn_out + out\n            else:\n                out = rnn_out\n        # out = self.rnn(out, training=training)        # (batch, downsampled_timestep, rnn_hidden_size)\n        out = tf.concat([out, inputs[2]], axis=-1)\n        out = self.dense0(out)\n        if self.binary:\n            out = self.dense1_0(out)\n        else:\n            out = self.dense1_1(out)\n        return out\n\n    def set_binary(self):\n        self.binary = True\n        if self.dense1_0.build == False:\n            self.dense1_0.build(input_shape=(None, self.hidden_size))\n\n    def set_multi(self):\n        self.binary = False\n        if self.dense1_1.build == False:\n            self.dense1_1.build(input_shape=(None, self.hidden_size))\n\n    def freeze_conv_timeseries(self):\n        for i in range(len(self.conv2d_nets)):\n            self.conv3d_nets[i].trainable = False\n        for i in range(len(self.conv1d_nets)):\n            self.conv1d_nets[i].trainable = False\n        self.rnn.trainable = False","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:16.471164Z","iopub.execute_input":"2025-08-03T16:09:16.471455Z","iopub.status.idle":"2025-08-03T16:09:16.495801Z","shell.execute_reply.started":"2025-08-03T16:09:16.471430Z","shell.execute_reply":"2025-08-03T16:09:16.495093Z"},"papermill":{"duration":0.027617,"end_time":"2025-08-03T02:51:39.745047","exception":false,"start_time":"2025-08-03T02:51:39.717430","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, (inputs, targets) in enumerate(type_train_ds):\n    if i == 0:\n        print(inputs[0].shape)\n        print(inputs[1].shape)\n        print(inputs[2].shape)\n        break","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:19.510691Z","iopub.execute_input":"2025-08-03T16:09:19.511278Z","iopub.status.idle":"2025-08-03T16:09:19.558087Z","shell.execute_reply.started":"2025-08-03T16:09:19.511252Z","shell.execute_reply":"2025-08-03T16:09:19.557431Z"},"papermill":{"duration":0.057592,"end_time":"2025-08-03T02:51:39.805872","exception":false,"start_time":"2025-08-03T02:51:39.748280","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/cmi-tf-datasets/sample_weight.json') as f:\n    sample_weight_dict = json.load(f)\n\ntype_sample_weight = sample_weight_dict[\"type_sample_weight\"]\ntype_class_weight = {0: type_sample_weight[0], 1: type_sample_weight[1]}\n\ngesture_sample_weight = sample_weight_dict[\"gesture_sample_weight\"]\ngesture_class_weight = {i: gesture_sample_weight[i] for i in range(len(gesture_sample_weight))}","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:19.730768Z","iopub.execute_input":"2025-08-03T16:09:19.731371Z","iopub.status.idle":"2025-08-03T16:09:19.738029Z","shell.execute_reply.started":"2025-08-03T16:09:19.731345Z","shell.execute_reply":"2025-08-03T16:09:19.737452Z"},"papermill":{"duration":0.015952,"end_time":"2025-08-03T02:51:39.825220","exception":false,"start_time":"2025-08-03T02:51:39.809268","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def add_type_sample_weight(x, y):\n    y_int = tf.cast(y, tf.int32)\n    weight = tf.gather([type_class_weight[0], type_class_weight[1]], y_int)\n    return x, y, weight\n\ndef add_gesture_sample_weight(x, y):\n    y_arg = tf.argmax(y)\n    weight = tf.gather(gesture_sample_weight, y_arg)\n    return x, y, weight","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:21.310311Z","iopub.execute_input":"2025-08-03T16:09:21.310593Z","iopub.status.idle":"2025-08-03T16:09:21.315259Z","shell.execute_reply.started":"2025-08-03T16:09:21.310573Z","shell.execute_reply":"2025-08-03T16:09:21.314509Z"},"papermill":{"duration":0.008841,"end_time":"2025-08-03T02:51:39.837647","exception":false,"start_time":"2025-08-03T02:51:39.828806","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"type_train_ds = type_train_ds.unbatch().map(add_type_sample_weight).batch(16)\ntype_valid_ds = type_valid_ds.unbatch().map(add_type_sample_weight).batch(16)","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:21.505566Z","iopub.execute_input":"2025-08-03T16:09:21.505827Z","iopub.status.idle":"2025-08-03T16:09:21.592542Z","shell.execute_reply.started":"2025-08-03T16:09:21.505808Z","shell.execute_reply":"2025-08-03T16:09:21.592014Z"},"papermill":{"duration":0.093248,"end_time":"2025-08-03T02:51:39.934050","exception":false,"start_time":"2025-08-03T02:51:39.840802","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# gesture_train_ds = gesture_train_ds.unbatch().map(add_gesture_sample_weight).batch(16)\n# gesture_valid_ds = gesture_valid_ds.unbatch().map(add_gesture_sample_weight).batch(16)","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:21.669830Z","iopub.execute_input":"2025-08-03T16:09:21.670046Z","iopub.status.idle":"2025-08-03T16:09:21.673194Z","shell.execute_reply.started":"2025-08-03T16:09:21.670031Z","shell.execute_reply":"2025-08-03T16:09:21.672455Z"},"papermill":{"duration":0.009056,"end_time":"2025-08-03T02:51:39.946782","exception":false,"start_time":"2025-08-03T02:51:39.937726","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def scheduler(epoch):\n    lr = 0.001\n    if epoch < 20:\n        return lr\n    elif 20 <= epoch and epoch < 40:\n        return lr * (1/2)\n    elif 40 <= epoch and epoch < 60:\n        return lr * (1/4)\n    elif 60 <= epoch and epoch < 80:\n        return lr * (1/8)\n    else:\n        return lr * (1/16)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-03T16:09:21.825466Z","iopub.execute_input":"2025-08-03T16:09:21.825729Z","iopub.status.idle":"2025-08-03T16:09:21.830403Z","shell.execute_reply.started":"2025-08-03T16:09:21.825707Z","shell.execute_reply":"2025-08-03T16:09:21.829621Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, CategoricalFocalCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import BinaryAccuracy, F1Score, AUC\n\nmodel = RNNModel(kernel_size2d=3, kernel_size1d=3, filters_2d=[8, 16], dropout=0.2,\n                 filters_1d=[32, 64, 128], num_rnn_layers=2, rnn_hidden_size=128, mode=\"GRU\", \n                 bidirectional=True, hidden_size=512, regularizer=\"l2\", \n                 l1_penalty=1e-6, l2_penalty=1e-4, binary=False)\nmodel.build(input_shapes=((None, 130, 8, 8, 5), (None, 130, 7), (None, 6)))\n# model.set_multi()\nmodel.compile(loss=CategoricalFocalCrossentropy(alpha=gesture_sample_weight, \n                                                gamma=2,\n                                                label_smoothing=0.2),\n              optimizer=Adam(learning_rate=0.0005),\n              metrics=[\"accuracy\"])\nmodel.summary()\n# model.freeze_conv_timeseries()","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:23.750843Z","iopub.execute_input":"2025-08-03T16:09:23.751139Z","iopub.status.idle":"2025-08-03T16:09:24.041809Z","shell.execute_reply.started":"2025-08-03T16:09:23.751117Z","shell.execute_reply":"2025-08-03T16:09:24.041269Z"},"papermill":{"duration":1.537871,"end_time":"2025-08-03T02:51:41.487729","exception":false,"start_time":"2025-08-03T02:51:39.949858","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\ncheckpoint_filepath = \"/kaggle/working/cmi_best_model.weights.h5\"\ncheckpoint_callback = ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor=\"val_accuracy\",\n    save_best_only=True,\n    save_weights_only=True,\n    mode=\"max\",\n    verbose=1\n)\n\nlr_callback = LearningRateScheduler(scheduler, verbose=0)\n\nhistory = model.fit(gesture_train_ds, epochs=100, \n                    validation_data=gesture_valid_ds,\n                    callbacks=[checkpoint_callback])\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2025-08-03T16:09:26.440165Z","iopub.execute_input":"2025-08-03T16:09:26.440856Z","iopub.status.idle":"2025-08-03T16:27:36.396904Z","shell.execute_reply.started":"2025-08-03T16:09:26.440833Z","shell.execute_reply":"2025-08-03T16:27:36.395805Z"},"papermill":{"duration":2581.642964,"end_time":"2025-08-03T03:34:43.135031","exception":false,"start_time":"2025-08-03T02:51:41.492067","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open('/kaggle/input/cmi-tf-datasets/mapping.json') as f:\n    mapping_dict = json.load(f)\n\ngesture_mapping = mapping_dict[\"gesture_mapping\"]\ninv_gesture_mapping = {value: key for key, value in gesture_mapping.items()}\n\nnum2gesture = np.vectorize(lambda x: inv_gesture_mapping[x])","metadata":{"execution":{"iopub.status.busy":"2025-08-03T15:42:59.977601Z","iopub.status.idle":"2025-08-03T15:42:59.977944Z","shell.execute_reply.started":"2025-08-03T15:42:59.977758Z","shell.execute_reply":"2025-08-03T15:42:59.977773Z"},"papermill":{"duration":1.007517,"end_time":"2025-08-03T03:34:45.123831","exception":false,"start_time":"2025-08-03T03:34:44.116314","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"non_target_gestures = [\"Drink from bottle/cup\", \"Glasses on/off\", \"Pull air toward your face\",\n                       \"Pinch knee/leg skin\", \"Scratch knee/leg skin\", \"Write name on leg\",\n                       \"Text on phone\", \"Feel around in tray and pull out an object\",\n                       \"Write name in air\", \"Wave hello\"]\n\ndef map_non_target(y_ind):\n    y_pred = inv_gesture_mapping[y_ind]\n    if y_ind == 3:\n        y_ind = 2\n    elif y_ind == 4:\n        y_ind = 3\n    elif y_ind == 6:\n        y_ind = 4\n    elif y_ind == 7:\n        y_ind = 5\n    elif y_ind == 9:\n        y_ind = 6\n    elif y_ind == 10:\n        y_ind = 7\n    if y_pred in non_target_gestures:\n        y_ind = 8\n    return y_ind\n\nvectorize_map_non_target = np.vectorize(map_non_target)","metadata":{"execution":{"iopub.status.busy":"2025-08-03T15:42:59.978941Z","iopub.status.idle":"2025-08-03T15:42:59.979183Z","shell.execute_reply.started":"2025-08-03T15:42:59.979050Z","shell.execute_reply":"2025-08-03T15:42:59.979059Z"},"papermill":{"duration":0.893904,"end_time":"2025-08-03T03:34:46.958634","exception":false,"start_time":"2025-08-03T03:34:46.064730","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"conf_tensor = np.zeros((9, 9), dtype=np.int32)\nfor i, (inputs, labels) in enumerate(gesture_valid_ds):\n    labels_pred = model.predict(inputs, verbose=0)\n    labels_pred = tf.argmax(labels_pred, axis=-1).numpy()\n    labels_pred = vectorize_map_non_target(labels_pred)\n    labels_true = tf.argmax(labels, axis=-1).numpy()\n    labels_true = vectorize_map_non_target(labels_true)\n    conf_tensor += tf.math.confusion_matrix(labels_true, labels_pred, num_classes=9)","metadata":{"execution":{"iopub.execute_input":"2025-08-03T03:34:48.820335Z","iopub.status.busy":"2025-08-03T03:34:48.819956Z","iopub.status.idle":"2025-08-03T03:34:57.319106Z","shell.execute_reply":"2025-08-03T03:34:57.317933Z"},"papermill":{"duration":9.433641,"end_time":"2025-08-03T03:34:57.320803","exception":false,"start_time":"2025-08-03T03:34:47.887162","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"precisions = []\nrecalls = []\nf1s = []\n\nfor i in range(9):\n    column = conf_tensor[i, :]\n    row = conf_tensor[:, i]\n    precision = column[i] / tf.math.reduce_sum(column)\n    recall = row[i] / tf.math.reduce_sum(row)\n    inv_f1 = (1/precision + 1/recall)/2\n    f1 = 1/inv_f1\n    precisions.append(precision)\n    recalls.append(recall)\n    f1s.append(f1)\nprint(f\"F1 score mean: {np.round(np.mean(f1s), 3)}\")","metadata":{"execution":{"iopub.execute_input":"2025-08-03T03:34:59.169858Z","iopub.status.busy":"2025-08-03T03:34:59.164976Z","iopub.status.idle":"2025-08-03T03:34:59.221689Z","shell.execute_reply":"2025-08-03T03:34:59.220888Z"},"papermill":{"duration":1.01372,"end_time":"2025-08-03T03:34:59.223013","exception":false,"start_time":"2025-08-03T03:34:58.209293","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import os\n# save_path = os.path.join(\"/kaggle/working/\", \"cmi_model.weights.h5\")\n# model.save_weights(save_path)","metadata":{"execution":{"iopub.execute_input":"2025-08-03T03:35:01.158040Z","iopub.status.busy":"2025-08-03T03:35:01.157743Z","iopub.status.idle":"2025-08-03T03:35:01.161379Z","shell.execute_reply":"2025-08-03T03:35:01.160607Z"},"papermill":{"duration":0.98532,"end_time":"2025-08-03T03:35:01.162808","exception":false,"start_time":"2025-08-03T03:35:00.177488","status":"completed"},"tags":[]},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_model = RNNModel(kernel_size2d=3, kernel_size1d=3, filters_2d=[8, 16], dropout=0.2,\n                     filters_1d=[32, 64, 128], num_rnn_layers=2, rnn_hidden_size=128, mode=\"GRU\", \n                     bidirectional=True, hidden_size=512, regularizer=\"l2\", \n                     l1_penalty=1e-6, l2_penalty=1e-4, binary=True)\nnew_model.build(input_shapes=((None, 100, 8, 8, 5), (None, 100, 7), (None, 6)))\nnew_model.load_weights(checkpoint_filepath)\nnew_model.summary()","metadata":{"execution":{"iopub.execute_input":"2025-08-03T03:35:02.991023Z","iopub.status.busy":"2025-08-03T03:35:02.990712Z","iopub.status.idle":"2025-08-03T03:35:03.213727Z","shell.execute_reply":"2025-08-03T03:35:03.212945Z"},"papermill":{"duration":1.17719,"end_time":"2025-08-03T03:35:03.214875","exception":false,"start_time":"2025-08-03T03:35:02.037685","status":"completed"},"tags":[]},"outputs":[],"execution_count":null}]}